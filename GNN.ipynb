{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8e9tfWcjPUs",
        "colab_type": "text"
      },
      "source": [
        "Make a copy of this notebook. When running this notebook on Colab, ensure that you've set your Runtime > Change runtime type to Python 3 and GPU.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oLWZWPPqo-l",
        "colab_type": "code",
        "outputId": "ffb05ef1-6586-4ae8-e9c3-a0c58bf11868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install --verbose --no-cache-dir torch-scatter\n",
        "!pip install --verbose --no-cache-dir torch-sparse\n",
        "!pip install --verbose --no-cache-dir torch-cluster\n",
        "!pip install torch-geometric\n",
        "!pip install tensorboardX\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-9e4a6elk\n",
            "Created temporary directory: /tmp/pip-req-tracker-ujc7wxu4\n",
            "Created requirements tracker '/tmp/pip-req-tracker-ujc7wxu4'\n",
            "Created temporary directory: /tmp/pip-install-_ya7nc4t\n",
            "1 location(s) to search for versions of torch-scatter:\n",
            "* https://pypi.org/simple/torch-scatter/\n",
            "Getting page https://pypi.org/simple/torch-scatter/\n",
            "Found index url https://pypi.org/simple\n",
            "Starting new HTTPS connection (1): pypi.org:443\n",
            "https://pypi.org:443 \"GET /simple/torch-scatter/ HTTP/1.1\" 200 1284\n",
            "Analyzing links from page https://pypi.org/simple/torch-scatter/\n",
            "  Found link https://files.pythonhosted.org/packages/29/96/566ac314e796d4b07209a3b88cc7a8d2e8582d55819e33f72e6c0e8d8216/torch_scatter-0.3.0.tar.gz#sha256=9e5e5a6efa4ef45f584e8611f83690d799370dd122b862646751ae112b685b50 (from https://pypi.org/simple/torch-scatter/), version: 0.3.0\n",
            "  Found link https://files.pythonhosted.org/packages/6a/b0/ecffacddf573c147c70c6e43ce05d24f007155ce3fb436959d3d2a24da46/torch_scatter-1.0.2.tar.gz#sha256=ccda794c25265b3450206b7fb0bf74f16a0b45f3f72d9547a42e44648a32faee (from https://pypi.org/simple/torch-scatter/), version: 1.0.2\n",
            "  Found link https://files.pythonhosted.org/packages/08/09/07b106f3e74246f4ecf6517013a053b6dd7486c4f889d81f39adc662431f/torch_scatter-1.0.3.tar.gz#sha256=e626993194819ba65cdf89a52fbbb7780569d9e157bc63dbef13ead6b7a33930 (from https://pypi.org/simple/torch-scatter/), version: 1.0.3\n",
            "  Found link https://files.pythonhosted.org/packages/2d/70/df2bc259d9606f00854ca43b6839f9047ec44900563435e0067584c93864/torch_scatter-1.0.4.tar.gz#sha256=ec004d687e47da9d5477407849d815629fc8b571ee87aeeebf6af8ed6f16defc (from https://pypi.org/simple/torch-scatter/), version: 1.0.4\n",
            "  Found link https://files.pythonhosted.org/packages/2f/97/c50a6aeaedc6924180c6f5810d2a7405ce11aa9b82ba4284badad549d665/torch_scatter-1.1.0.tar.gz#sha256=e534cc2ecb2f9d9b559b1513cd411737d26ea5585d1d65ff571fec55f42a49de (from https://pypi.org/simple/torch-scatter/), version: 1.1.0\n",
            "  Found link https://files.pythonhosted.org/packages/91/5f/eb1d3ef3810cb1165859d40db4d9ee6d7f1dfef97d7e5c34010055f43d95/torch_scatter-1.1.1.tar.gz#sha256=9db7f2c0a5cddf6cfde633e33db7c2c94eaab163e9f8edb46460d6414cc97917 (from https://pypi.org/simple/torch-scatter/), version: 1.1.1\n",
            "  Found link https://files.pythonhosted.org/packages/d4/83/67eeea00c2db1959e2ff95d8680dbd756977bfab254bda8658f09dc3bc11/torch_scatter-1.1.2.tar.gz#sha256=766c2476f5da5ffc25fa8e249ccf50f594031cdce3922abb23559e8e3b14337a (from https://pypi.org/simple/torch-scatter/), version: 1.1.2\n",
            "  Found link https://files.pythonhosted.org/packages/07/c0/f7ac424496f4a3bcb31aa993fba29077a6d42fc2624c66e90b58a566a98e/torch_scatter-1.2.0.tar.gz#sha256=3a0259105d07d264c740eec8e4267260a5c144cf55472abd26022fff4fd73281 (from https://pypi.org/simple/torch-scatter/), version: 1.2.0\n",
            "  Found link https://files.pythonhosted.org/packages/24/b7/680c3b392a4b55a0ebfb480aabb0d5c188e94bb21790104175c8cd614947/torch_scatter-1.3.0.tar.gz#sha256=bf7d561b8ef12b39a99f5797c90b989a0ce2c3ee4de74dff3b170f2d8566e1d4 (from https://pypi.org/simple/torch-scatter/), version: 1.3.0\n",
            "  Found link https://files.pythonhosted.org/packages/35/d4/750403a8aa32cdb3d2d05849c6a10e4e0604de5e0cc94b81a0d0d69a75f3/torch_scatter-1.3.1.tar.gz#sha256=54cbad248350165ddc921ded3fe7a69be5d30c6536273a1a3282e375289f86ec (from https://pypi.org/simple/torch-scatter/), version: 1.3.1\n",
            "  Found link https://files.pythonhosted.org/packages/30/d9/1d5fd4d183dabd9e0a1f7008ecf83318432359f4cc27480e3f2212f44d9c/torch_scatter-1.3.2.tar.gz#sha256=890e8f9da2d57431912182960b71bf6c56397de42c2464907a6e9c583164bf06 (from https://pypi.org/simple/torch-scatter/), version: 1.3.2\n",
            "  Found link https://files.pythonhosted.org/packages/b8/c3/8bad887ffa55c86f120ef5ae252dc0e357b3bd956d9fbf45242bacc46290/torch_scatter-1.4.0.tar.gz#sha256=5999ef256154e5a99445118c1a53f95cf0f95ef7b5cd8d3b256101125479cc2e (from https://pypi.org/simple/torch-scatter/), version: 1.4.0\n",
            "Given no hashes to check 12 links for project 'torch-scatter': discarding no candidates\n",
            "Using version 1.4.0 (newest of versions: 0.3.0, 1.0.2, 1.0.3, 1.0.4, 1.1.0, 1.1.1, 1.1.2, 1.2.0, 1.3.0, 1.3.1, 1.3.2, 1.4.0)\n",
            "Collecting torch-scatter\n",
            "  Created temporary directory: /tmp/pip-unpack-ogag0ixe\n",
            "  Starting new HTTPS connection (1): files.pythonhosted.org:443\n",
            "  https://files.pythonhosted.org:443 \"GET /packages/b8/c3/8bad887ffa55c86f120ef5ae252dc0e357b3bd956d9fbf45242bacc46290/torch_scatter-1.4.0.tar.gz HTTP/1.1\" 200 14692\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/c3/8bad887ffa55c86f120ef5ae252dc0e357b3bd956d9fbf45242bacc46290/torch_scatter-1.4.0.tar.gz\n",
            "  Added torch-scatter from https://files.pythonhosted.org/packages/b8/c3/8bad887ffa55c86f120ef5ae252dc0e357b3bd956d9fbf45242bacc46290/torch_scatter-1.4.0.tar.gz#sha256=5999ef256154e5a99445118c1a53f95cf0f95ef7b5cd8d3b256101125479cc2e to build tracker '/tmp/pip-req-tracker-ujc7wxu4'\n",
            "    Running setup.py (path:/tmp/pip-install-_ya7nc4t/torch-scatter/setup.py) egg_info for package torch-scatter\n",
            "    Running command python setup.py egg_info\n",
            "    running egg_info\n",
            "    creating /tmp/pip-install-_ya7nc4t/torch-scatter/pip-egg-info/torch_scatter.egg-info\n",
            "    writing /tmp/pip-install-_ya7nc4t/torch-scatter/pip-egg-info/torch_scatter.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-install-_ya7nc4t/torch-scatter/pip-egg-info/torch_scatter.egg-info/dependency_links.txt\n",
            "    writing top-level names to /tmp/pip-install-_ya7nc4t/torch-scatter/pip-egg-info/torch_scatter.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-install-_ya7nc4t/torch-scatter/pip-egg-info/torch_scatter.egg-info/SOURCES.txt'\n",
            "    reading manifest file '/tmp/pip-install-_ya7nc4t/torch-scatter/pip-egg-info/torch_scatter.egg-info/SOURCES.txt'\n",
            "    reading manifest template 'MANIFEST.in'\n",
            "    writing manifest file '/tmp/pip-install-_ya7nc4t/torch-scatter/pip-egg-info/torch_scatter.egg-info/SOURCES.txt'\n",
            "  Source in /tmp/pip-install-_ya7nc4t/torch-scatter has version 1.4.0, which satisfies requirement torch-scatter from https://files.pythonhosted.org/packages/b8/c3/8bad887ffa55c86f120ef5ae252dc0e357b3bd956d9fbf45242bacc46290/torch_scatter-1.4.0.tar.gz#sha256=5999ef256154e5a99445118c1a53f95cf0f95ef7b5cd8d3b256101125479cc2e\n",
            "  Removed torch-scatter from https://files.pythonhosted.org/packages/b8/c3/8bad887ffa55c86f120ef5ae252dc0e357b3bd956d9fbf45242bacc46290/torch_scatter-1.4.0.tar.gz#sha256=5999ef256154e5a99445118c1a53f95cf0f95ef7b5cd8d3b256101125479cc2e from build tracker '/tmp/pip-req-tracker-ujc7wxu4'\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Created temporary directory: /tmp/pip-wheel-0z0f63pa\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l  Destination directory: /tmp/pip-wheel-0z0f63pa\n",
            "  Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-_ya7nc4t/torch-scatter/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-_ya7nc4t/torch-scatter/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-0z0f63pa --python-tag cp36\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib.linux-x86_64-3.6\n",
            "  creating build/lib.linux-x86_64-3.6/test\n",
            "  copying test/__init__.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_std.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/utils.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_forward.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_broadcasting.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_max_min.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_logsumexp.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_multi_gpu.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_backward.py -> build/lib.linux-x86_64-3.6/test\n",
            "  creating build/lib.linux-x86_64-3.6/torch_scatter\n",
            "  copying torch_scatter/__init__.py -> build/lib.linux-x86_64-3.6/torch_scatter\n",
            "  copying torch_scatter/div.py -> build/lib.linux-x86_64-3.6/torch_scatter\n",
            "  copying torch_scatter/mul.py -> build/lib.linux-x86_64-3.6/torch_scatter\n",
            "  copying torch_scatter/max.py -> build/lib.linux-x86_64-3.6/torch_scatter\n",
            "  copying torch_scatter/mean.py -> build/lib.linux-x86_64-3.6/torch_scatter\n",
            "  copying torch_scatter/sub.py -> build/lib.linux-x86_64-3.6/torch_scatter\n",
            "  copying torch_scatter/logsumexp.py -> build/lib.linux-x86_64-3.6/torch_scatter\n",
            "  copying torch_scatter/std.py -> build/lib.linux-x86_64-3.6/torch_scatter\n",
            "  copying torch_scatter/min.py -> build/lib.linux-x86_64-3.6/torch_scatter\n",
            "  copying torch_scatter/add.py -> build/lib.linux-x86_64-3.6/torch_scatter\n",
            "  creating build/lib.linux-x86_64-3.6/torch_scatter/composite\n",
            "  copying torch_scatter/composite/__init__.py -> build/lib.linux-x86_64-3.6/torch_scatter/composite\n",
            "  copying torch_scatter/composite/softmax.py -> build/lib.linux-x86_64-3.6/torch_scatter/composite\n",
            "  creating build/lib.linux-x86_64-3.6/torch_scatter/utils\n",
            "  copying torch_scatter/utils/__init__.py -> build/lib.linux-x86_64-3.6/torch_scatter/utils\n",
            "  copying torch_scatter/utils/ext.py -> build/lib.linux-x86_64-3.6/torch_scatter/utils\n",
            "  copying torch_scatter/utils/gen.py -> build/lib.linux-x86_64-3.6/torch_scatter/utils\n",
            "  running build_ext\n",
            "  building 'torch_scatter.scatter_cpu' extension\n",
            "  creating build/temp.linux-x86_64-3.6\n",
            "  creating build/temp.linux-x86_64-3.6/cpu\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c cpu/scatter.cpp -o build/temp.linux-x86_64-3.6/cpu/scatter.o -Wno-unused-variable -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=scatter_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cpu/scatter.o -o build/lib.linux-x86_64-3.6/torch_scatter/scatter_cpu.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_scatter.scatter_cuda' extension\n",
            "  creating build/temp.linux-x86_64-3.6/cuda\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/scatter.cpp -o build/temp.linux-x86_64-3.6/cuda/scatter.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=scatter_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/scatter_kernel.cu -o build/temp.linux-x86_64-3.6/cuda/scatter_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=scatter_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cuda/scatter.o build/temp.linux-x86_64-3.6/cuda/scatter_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/torch_scatter/scatter_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/__init__.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_std.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/utils.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_forward.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_broadcasting.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_max_min.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_logsumexp.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_multi_gpu.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_backward.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/__init__.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/div.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/mul.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/max.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/scatter_cpu.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/scatter_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_scatter/composite\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/composite/__init__.py -> build/bdist.linux-x86_64/wheel/torch_scatter/composite\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/composite/softmax.py -> build/bdist.linux-x86_64/wheel/torch_scatter/composite\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/mean.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/sub.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/logsumexp.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/std.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/min.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/add.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_scatter/utils\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/utils/__init__.py -> build/bdist.linux-x86_64/wheel/torch_scatter/utils\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/utils/ext.py -> build/bdist.linux-x86_64/wheel/torch_scatter/utils\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/utils/gen.py -> build/bdist.linux-x86_64/wheel/torch_scatter/utils\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  writing torch_scatter.egg-info/PKG-INFO\n",
            "  writing dependency_links to torch_scatter.egg-info/dependency_links.txt\n",
            "  writing top-level names to torch_scatter.egg-info/top_level.txt\n",
            "  reading manifest file 'torch_scatter.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  writing manifest file 'torch_scatter.egg-info/SOURCES.txt'\n",
            "  Copying torch_scatter.egg-info to build/bdist.linux-x86_64/wheel/torch_scatter-1.4.0-py3.6.egg-info\n",
            "  running install_scripts\n",
            "  adding license file \"LICENSE\" (matched pattern \"LICEN[CS]E*\")\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_scatter-1.4.0.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-0z0f63pa/torch_scatter-1.4.0-cp36-cp36m-linux_x86_64.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'test/__init__.py'\n",
            "  adding 'test/test_backward.py'\n",
            "  adding 'test/test_broadcasting.py'\n",
            "  adding 'test/test_forward.py'\n",
            "  adding 'test/test_logsumexp.py'\n",
            "  adding 'test/test_max_min.py'\n",
            "  adding 'test/test_multi_gpu.py'\n",
            "  adding 'test/test_std.py'\n",
            "  adding 'test/utils.py'\n",
            "  adding 'torch_scatter/__init__.py'\n",
            "  adding 'torch_scatter/add.py'\n",
            "  adding 'torch_scatter/div.py'\n",
            "  adding 'torch_scatter/logsumexp.py'\n",
            "  adding 'torch_scatter/max.py'\n",
            "  adding 'torch_scatter/mean.py'\n",
            "  adding 'torch_scatter/min.py'\n",
            "  adding 'torch_scatter/mul.py'\n",
            "  adding 'torch_scatter/scatter_cpu.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_scatter/scatter_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_scatter/std.py'\n",
            "  adding 'torch_scatter/sub.py'\n",
            "  adding 'torch_scatter/composite/__init__.py'\n",
            "  adding 'torch_scatter/composite/softmax.py'\n",
            "  adding 'torch_scatter/utils/__init__.py'\n",
            "  adding 'torch_scatter/utils/ext.py'\n",
            "  adding 'torch_scatter/utils/gen.py'\n",
            "  adding 'torch_scatter-1.4.0.dist-info/LICENSE'\n",
            "  adding 'torch_scatter-1.4.0.dist-info/METADATA'\n",
            "  adding 'torch_scatter-1.4.0.dist-info/WHEEL'\n",
            "  adding 'torch_scatter-1.4.0.dist-info/top_level.txt'\n",
            "  adding 'torch_scatter-1.4.0.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-1.4.0-cp36-cp36m-linux_x86_64.whl size=2875365 sha256=ac52253067139411729bfdae3d8ab0fec7b21a901b5924dbddbfd676291ec27e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9e4a6elk/wheels/25/00/c4/1637b4b3003f29092f4fe2ad4b40dd10906269c1ac2dc82941\n",
            "  Removing source in /tmp/pip-install-_ya7nc4t/torch-scatter\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "\n",
            "Successfully installed torch-scatter-1.4.0\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-ujc7wxu4'\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-mkrj4_bg\n",
            "Created temporary directory: /tmp/pip-req-tracker-lq791qm7\n",
            "Created requirements tracker '/tmp/pip-req-tracker-lq791qm7'\n",
            "Created temporary directory: /tmp/pip-install-88ym0fal\n",
            "1 location(s) to search for versions of torch-sparse:\n",
            "* https://pypi.org/simple/torch-sparse/\n",
            "Getting page https://pypi.org/simple/torch-sparse/\n",
            "Found index url https://pypi.org/simple\n",
            "Starting new HTTPS connection (1): pypi.org:443\n",
            "https://pypi.org:443 \"GET /simple/torch-sparse/ HTTP/1.1\" 200 1096\n",
            "Analyzing links from page https://pypi.org/simple/torch-sparse/\n",
            "  Found link https://files.pythonhosted.org/packages/21/a6/af5865f7bc2dc45ea789ebb35bdf5d84c05e140d7d2ec7e5823d24db176f/torch_sparse-0.1.0.tar.gz#sha256=d774c4b05a96bf09e3c3becd2f48c65ed66b03195a2cfc4992ef57c9a8c6b399 (from https://pypi.org/simple/torch-sparse/), version: 0.1.0\n",
            "  Found link https://files.pythonhosted.org/packages/02/4f/89bcb156022a3960c4db852915c64ea78b4e993e0f8d7a83e60e6819fc11/torch_sparse-0.2.0.tar.gz#sha256=578fdc3522b06c948d43fbc360d0dcde8a89d9a2496ac468592bf3493baedd33 (from https://pypi.org/simple/torch-sparse/), version: 0.2.0\n",
            "  Found link https://files.pythonhosted.org/packages/8f/41/98db80cc9d9345c76445393661ce4dd3e08fc46fb17028e7706612063e4d/torch_sparse-0.2.1.tar.gz#sha256=01346234f0e76103304f8aa1099f22c0904d2fff8b36c5ec0230335149f526bc (from https://pypi.org/simple/torch-sparse/), version: 0.2.1\n",
            "  Found link https://files.pythonhosted.org/packages/73/5b/5b7b6c66148afaa5e2ed8a3e18e109361957d28e67032d92cb282d173f32/torch_sparse-0.2.2.tar.gz#sha256=11e87c0214a4491168f15726ddda6c771b5f34be728f3edbb4add203e46d924d (from https://pypi.org/simple/torch-sparse/), version: 0.2.2\n",
            "  Found link https://files.pythonhosted.org/packages/43/2a/bb2ead5b33c6932937c6c74199ebecd72bd4b3ab224842a50366e5b2af4a/torch_sparse-0.2.3.tar.gz#sha256=47b3f85b0c243d0c98798db722b0f066830f6b8ff9d298a6e2aed0662598e356 (from https://pypi.org/simple/torch-sparse/), version: 0.2.3\n",
            "  Found link https://files.pythonhosted.org/packages/73/72/e374662f6f47d9ac0e082a6d5c18d14e15c52863e89c6bc6957a0d2ed026/torch_sparse-0.2.4.tar.gz#sha256=5cae8b40a5d11b8917e0f4b95034b5842b052f42a089ce59f8c02f2cff00ca55 (from https://pypi.org/simple/torch-sparse/), version: 0.2.4\n",
            "  Found link https://files.pythonhosted.org/packages/b0/0a/2ff678e0d04e524dd2cf990a6202ced8c0ffe3fe6b08e02f25cc9fd27da0/torch_sparse-0.4.0.tar.gz#sha256=bf217539b4f714a1d6fac4d39ace3ad8033871717f44f8f365a2746056b9d805 (from https://pypi.org/simple/torch-sparse/), version: 0.4.0\n",
            "  Found link https://files.pythonhosted.org/packages/c7/3e/aa5449787910283d846a7c739899ccf8c53c914f8a7aee7bc500a32dc091/torch_sparse-0.4.1.tar.gz#sha256=4831fe4b78b86d4dff948d50fec042ef99b98e850495b400189456380ec397d4 (from https://pypi.org/simple/torch-sparse/), version: 0.4.1\n",
            "  Found link https://files.pythonhosted.org/packages/7d/c5/1f73917168aa9816f41e0696f266fa07d0ebfe8d25c3e63a0f08440534b9/torch_sparse-0.4.2.tar.gz#sha256=a652feb1b945995fb863dcbfdaa01de9096d5ed7230380ebf6d262e649eb4123 (from https://pypi.org/simple/torch-sparse/), version: 0.4.2\n",
            "  Found link https://files.pythonhosted.org/packages/08/4e/a268613fa6a92ffbc65b89e66fc8be5590801937185007f0f7bcb75ea21f/torch_sparse-0.4.3.tar.gz#sha256=87b63cb21f091b450271e75d42280c9ef165d61e6ae6dcb983ad2caedfd6eb0f (from https://pypi.org/simple/torch-sparse/), version: 0.4.3\n",
            "Given no hashes to check 10 links for project 'torch-sparse': discarding no candidates\n",
            "Using version 0.4.3 (newest of versions: 0.1.0, 0.2.0, 0.2.1, 0.2.2, 0.2.3, 0.2.4, 0.4.0, 0.4.1, 0.4.2, 0.4.3)\n",
            "Collecting torch-sparse\n",
            "  Created temporary directory: /tmp/pip-unpack-tkye7gx4\n",
            "  Starting new HTTPS connection (1): files.pythonhosted.org:443\n",
            "  https://files.pythonhosted.org:443 \"GET /packages/08/4e/a268613fa6a92ffbc65b89e66fc8be5590801937185007f0f7bcb75ea21f/torch_sparse-0.4.3.tar.gz HTTP/1.1\" 200 11018\n",
            "  Downloading https://files.pythonhosted.org/packages/08/4e/a268613fa6a92ffbc65b89e66fc8be5590801937185007f0f7bcb75ea21f/torch_sparse-0.4.3.tar.gz\n",
            "  Added torch-sparse from https://files.pythonhosted.org/packages/08/4e/a268613fa6a92ffbc65b89e66fc8be5590801937185007f0f7bcb75ea21f/torch_sparse-0.4.3.tar.gz#sha256=87b63cb21f091b450271e75d42280c9ef165d61e6ae6dcb983ad2caedfd6eb0f to build tracker '/tmp/pip-req-tracker-lq791qm7'\n",
            "    Running setup.py (path:/tmp/pip-install-88ym0fal/torch-sparse/setup.py) egg_info for package torch-sparse\n",
            "    Running command python setup.py egg_info\n",
            "    running egg_info\n",
            "    creating /tmp/pip-install-88ym0fal/torch-sparse/pip-egg-info/torch_sparse.egg-info\n",
            "    writing /tmp/pip-install-88ym0fal/torch-sparse/pip-egg-info/torch_sparse.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-install-88ym0fal/torch-sparse/pip-egg-info/torch_sparse.egg-info/dependency_links.txt\n",
            "    writing requirements to /tmp/pip-install-88ym0fal/torch-sparse/pip-egg-info/torch_sparse.egg-info/requires.txt\n",
            "    writing top-level names to /tmp/pip-install-88ym0fal/torch-sparse/pip-egg-info/torch_sparse.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-install-88ym0fal/torch-sparse/pip-egg-info/torch_sparse.egg-info/SOURCES.txt'\n",
            "    reading manifest file '/tmp/pip-install-88ym0fal/torch-sparse/pip-egg-info/torch_sparse.egg-info/SOURCES.txt'\n",
            "    reading manifest template 'MANIFEST.in'\n",
            "    writing manifest file '/tmp/pip-install-88ym0fal/torch-sparse/pip-egg-info/torch_sparse.egg-info/SOURCES.txt'\n",
            "  Source in /tmp/pip-install-88ym0fal/torch-sparse has version 0.4.3, which satisfies requirement torch-sparse from https://files.pythonhosted.org/packages/08/4e/a268613fa6a92ffbc65b89e66fc8be5590801937185007f0f7bcb75ea21f/torch_sparse-0.4.3.tar.gz#sha256=87b63cb21f091b450271e75d42280c9ef165d61e6ae6dcb983ad2caedfd6eb0f\n",
            "  Removed torch-sparse from https://files.pythonhosted.org/packages/08/4e/a268613fa6a92ffbc65b89e66fc8be5590801937185007f0f7bcb75ea21f/torch_sparse-0.4.3.tar.gz#sha256=87b63cb21f091b450271e75d42280c9ef165d61e6ae6dcb983ad2caedfd6eb0f from build tracker '/tmp/pip-req-tracker-lq791qm7'\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-sparse) (1.3.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-sparse) (1.17.4)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Created temporary directory: /tmp/pip-wheel-hflgj0wv\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l  Destination directory: /tmp/pip-wheel-hflgj0wv\n",
            "  Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-88ym0fal/torch-sparse/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-88ym0fal/torch-sparse/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-hflgj0wv --python-tag cp36\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib.linux-x86_64-3.6\n",
            "  creating build/lib.linux-x86_64-3.6/test\n",
            "  copying test/__init__.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/utils.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_spmm.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_coalesce.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_spspmm.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_eye.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_transpose.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_spspmm_spmm.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_convert.py -> build/lib.linux-x86_64-3.6/test\n",
            "  creating build/lib.linux-x86_64-3.6/torch_sparse\n",
            "  copying torch_sparse/__init__.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
            "  copying torch_sparse/spspmm.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
            "  copying torch_sparse/eye.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
            "  copying torch_sparse/spmm.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
            "  copying torch_sparse/coalesce.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
            "  copying torch_sparse/convert.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
            "  copying torch_sparse/transpose.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
            "  creating build/lib.linux-x86_64-3.6/torch_sparse/utils\n",
            "  copying torch_sparse/utils/__init__.py -> build/lib.linux-x86_64-3.6/torch_sparse/utils\n",
            "  copying torch_sparse/utils/unique.py -> build/lib.linux-x86_64-3.6/torch_sparse/utils\n",
            "  running build_ext\n",
            "  building 'torch_sparse.spspmm_cpu' extension\n",
            "  creating build/temp.linux-x86_64-3.6\n",
            "  creating build/temp.linux-x86_64-3.6/cpu\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c cpu/spspmm.cpp -o build/temp.linux-x86_64-3.6/cpu/spspmm.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=spspmm_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cpu/spspmm.o -o build/lib.linux-x86_64-3.6/torch_sparse/spspmm_cpu.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_sparse.spspmm_cuda' extension\n",
            "  creating build/temp.linux-x86_64-3.6/cuda\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/spspmm.cpp -o build/temp.linux-x86_64-3.6/cuda/spspmm.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=spspmm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/spspmm_kernel.cu -o build/temp.linux-x86_64-3.6/cuda/spspmm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=spspmm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cuda/spspmm.o build/temp.linux-x86_64-3.6/cuda/spspmm_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/torch_sparse/spspmm_cuda.cpython-36m-x86_64-linux-gnu.so -lcusparse -l cusparse\n",
            "  building 'torch_sparse.unique_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/unique.cpp -o build/temp.linux-x86_64-3.6/cuda/unique.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=unique_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/unique_kernel.cu -o build/temp.linux-x86_64-3.6/cuda/unique_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=unique_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cuda/unique.o build/temp.linux-x86_64-3.6/cuda/unique_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/torch_sparse/unique_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/__init__.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/utils.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_spmm.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_coalesce.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_spspmm.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_eye.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_transpose.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_spspmm_spmm.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_convert.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/__init__.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/spspmm_cpu.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/spspmm.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/eye.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/spmm.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/spspmm_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/unique_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/coalesce.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/convert.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_sparse/utils\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/utils/__init__.py -> build/bdist.linux-x86_64/wheel/torch_sparse/utils\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/utils/unique.py -> build/bdist.linux-x86_64/wheel/torch_sparse/utils\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/transpose.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  writing torch_sparse.egg-info/PKG-INFO\n",
            "  writing dependency_links to torch_sparse.egg-info/dependency_links.txt\n",
            "  writing requirements to torch_sparse.egg-info/requires.txt\n",
            "  writing top-level names to torch_sparse.egg-info/top_level.txt\n",
            "  reading manifest file 'torch_sparse.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  writing manifest file 'torch_sparse.egg-info/SOURCES.txt'\n",
            "  Copying torch_sparse.egg-info to build/bdist.linux-x86_64/wheel/torch_sparse-0.4.3-py3.6.egg-info\n",
            "  running install_scripts\n",
            "  adding license file \"LICENSE\" (matched pattern \"LICEN[CS]E*\")\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_sparse-0.4.3.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-hflgj0wv/torch_sparse-0.4.3-cp36-cp36m-linux_x86_64.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'test/__init__.py'\n",
            "  adding 'test/test_coalesce.py'\n",
            "  adding 'test/test_convert.py'\n",
            "  adding 'test/test_eye.py'\n",
            "  adding 'test/test_spmm.py'\n",
            "  adding 'test/test_spspmm.py'\n",
            "  adding 'test/test_spspmm_spmm.py'\n",
            "  adding 'test/test_transpose.py'\n",
            "  adding 'test/utils.py'\n",
            "  adding 'torch_sparse/__init__.py'\n",
            "  adding 'torch_sparse/coalesce.py'\n",
            "  adding 'torch_sparse/convert.py'\n",
            "  adding 'torch_sparse/eye.py'\n",
            "  adding 'torch_sparse/spmm.py'\n",
            "  adding 'torch_sparse/spspmm.py'\n",
            "  adding 'torch_sparse/spspmm_cpu.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_sparse/spspmm_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_sparse/transpose.py'\n",
            "  adding 'torch_sparse/unique_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_sparse/utils/__init__.py'\n",
            "  adding 'torch_sparse/utils/unique.py'\n",
            "  adding 'torch_sparse-0.4.3.dist-info/LICENSE'\n",
            "  adding 'torch_sparse-0.4.3.dist-info/METADATA'\n",
            "  adding 'torch_sparse-0.4.3.dist-info/WHEEL'\n",
            "  adding 'torch_sparse-0.4.3.dist-info/top_level.txt'\n",
            "  adding 'torch_sparse-0.4.3.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.4.3-cp36-cp36m-linux_x86_64.whl size=3966428 sha256=68fa3c1e49683697b86bf805af020fb56ae912b44ca6c65ea3ca97394198118e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mkrj4_bg/wheels/02/66/2b/befece01c2516f9fb3e7b4d150bb2b871221c73657c9cd7735\n",
            "  Removing source in /tmp/pip-install-88ym0fal/torch-sparse\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "\n",
            "Successfully installed torch-sparse-0.4.3\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-lq791qm7'\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-p0hposwq\n",
            "Created temporary directory: /tmp/pip-req-tracker-z7g757ut\n",
            "Created requirements tracker '/tmp/pip-req-tracker-z7g757ut'\n",
            "Created temporary directory: /tmp/pip-install-tr7fm8oe\n",
            "1 location(s) to search for versions of torch-cluster:\n",
            "* https://pypi.org/simple/torch-cluster/\n",
            "Getting page https://pypi.org/simple/torch-cluster/\n",
            "Found index url https://pypi.org/simple\n",
            "Starting new HTTPS connection (1): pypi.org:443\n",
            "https://pypi.org:443 \"GET /simple/torch-cluster/ HTTP/1.1\" 200 2174\n",
            "Analyzing links from page https://pypi.org/simple/torch-cluster/\n",
            "  Found link https://files.pythonhosted.org/packages/58/77/1ddc3390129653d1e0e1e0c8063d47a2f40abc888d95b4a2fba774e215df/torch_cluster-0.1.1.tar.gz#sha256=f4f64eabc4c380bff9863d3ce9b93b0a65c7ea6f797f9ee053dc74d7d92ea928 (from https://pypi.org/simple/torch-cluster/), version: 0.1.1\n",
            "  Found link https://files.pythonhosted.org/packages/ac/92/c583aabacb052afed67db146662c23625ad861a74140e338996816a879f4/torch_cluster-0.2.3.tar.gz#sha256=43d9840078f962abfced55043d8320f80c7f91aa7f54398b9ad631ee577bbfb1 (from https://pypi.org/simple/torch-cluster/), version: 0.2.3\n",
            "  Found link https://files.pythonhosted.org/packages/6e/9b/493def262b256290ad6913c9f36b774af6f52d9d46d3fee31b77b3803eb0/torch_cluster-0.2.4.tar.gz#sha256=f421986d71a644b72c69551f09df31eb8657203d59d639aac33192192ed675b5 (from https://pypi.org/simple/torch-cluster/), version: 0.2.4\n",
            "  Found link https://files.pythonhosted.org/packages/8a/2c/ddf6e6fc9c4af6c37a20996100cf6a6427accd7939470bc99071d3487753/torch_cluster-1.0.1.tar.gz#sha256=04cf3ad486eff6cc6069e3d1c18a2acd7662169f36d02a13f3a7adaabfc06b91 (from https://pypi.org/simple/torch-cluster/), version: 1.0.1\n",
            "  Found link https://files.pythonhosted.org/packages/87/9d/e488a5186684632e3e0f14eaec125936cf25a3a24552afd26e7bb426d2ee/torch_cluster-1.0.3.tar.gz#sha256=795264f9e9f36eb44aeb28716d68ea93cd6dc7f75c8e05e0d16eb0597ffcd1a6 (from https://pypi.org/simple/torch-cluster/), version: 1.0.3\n",
            "  Found link https://files.pythonhosted.org/packages/7b/95/bca3179ce501792bf268d37f18cc82577c289fa093bfdcfc26e375019da5/torch_cluster-1.1.1.tar.gz#sha256=e919f64153fd97efe958a509a0a558a31bf5f2dbe2deeff09d300e33d3994b14 (from https://pypi.org/simple/torch-cluster/), version: 1.1.1\n",
            "  Found link https://files.pythonhosted.org/packages/36/b0/25ca8b811059e001f1e3285ac3036b6969fb21350e411c6881ba2b9be3c3/torch_cluster-1.1.2.tar.gz#sha256=082c4e71079cd1bed89da4178b3391361fa6aac5ae2edb783c08fed3da5b93c4 (from https://pypi.org/simple/torch-cluster/), version: 1.1.2\n",
            "  Found link https://files.pythonhosted.org/packages/e2/4f/5205f832d3eef871fe71564aa9fb8504a65be5e95be09800e125e224e634/torch_cluster-1.1.3.tar.gz#sha256=d5c80159f91e329bcc95b316a29ecf466257598680b3b5fb2ea137a585037c78 (from https://pypi.org/simple/torch-cluster/), version: 1.1.3\n",
            "  Found link https://files.pythonhosted.org/packages/d0/e1/495ecc73f1e5534ecbedf1a301557d6c9fc93417467e5107fd9ac54fcbfa/torch_cluster-1.1.4.tar.gz#sha256=a298694afe91f146be3921b8c9da06051958b7598c6e69a9af5833a1af56e7f3 (from https://pypi.org/simple/torch-cluster/), version: 1.1.4\n",
            "  Found link https://files.pythonhosted.org/packages/a6/b3/de9c051d1df504d78542d178231f2ae7d08a411c9ca59219028742886947/torch_cluster-1.1.5.tar.gz#sha256=b67d6c89b71e4146dcfa078cc6a201a1647d888441a9f278b30770f91c7978a1 (from https://pypi.org/simple/torch-cluster/), version: 1.1.5\n",
            "  Found link https://files.pythonhosted.org/packages/96/de/9506fa869cf52edc58c2517b41c0ec1c7678c05b95aff000a509e4238765/torch_cluster-1.2.1.tar.gz#sha256=371b438113bcb7cab1b6931740e9194972f0f7349e1d033437a4196d7d693130 (from https://pypi.org/simple/torch-cluster/), version: 1.2.1\n",
            "  Found link https://files.pythonhosted.org/packages/33/b7/05b9ce9afc76f5709efe04d6344fbed09ea217f916f94e63f2fe9659eb62/torch_cluster-1.2.2.tar.gz#sha256=a1e39e16a7ade806a852117fe16fe2b505fd4bc43bc4207f48fecb0f6b2e1f64 (from https://pypi.org/simple/torch-cluster/), version: 1.2.2\n",
            "  Found link https://files.pythonhosted.org/packages/67/19/a0b1e3a7633ced39d9977ce0b98a1b3e343f0772f4090b0a2d421ac5b56d/torch_cluster-1.2.3.tar.gz#sha256=f8a6b5f47bf6a2a396301d0f4ec0733a650f7a5ae84b08b8625408b8979747ea (from https://pypi.org/simple/torch-cluster/), version: 1.2.3\n",
            "  Found link https://files.pythonhosted.org/packages/32/c8/9b3af10be647326dd807bb2fe7ced8ae4c3fd74178dba884621749afc4d7/torch_cluster-1.2.4.tar.gz#sha256=4e5f8c15b28329b269adecadd64917cb5373c6438a5fdf463f633bd4e73c4ae6 (from https://pypi.org/simple/torch-cluster/), version: 1.2.4\n",
            "  Found link https://files.pythonhosted.org/packages/93/f9/89319a7344e5bcda090fb3996c4271b1fda238ad90401a315c9af1ce4137/torch_cluster-1.3.0.tar.gz#sha256=7b0e1b7061bf8c2754d63a66159f47757ce28b072bc37921fbcc59974eb2d342 (from https://pypi.org/simple/torch-cluster/), version: 1.3.0\n",
            "  Found link https://files.pythonhosted.org/packages/6b/3b/a34740494a1b25cb2ef4ed09e5d5ef6bc75be884f6b25bd93a7acdf03134/torch_cluster-1.4.0.tar.gz#sha256=c256d61f20193b104a2f4c610b4ad95fa3cbaeb72b2ae9bf3d254cb3d573e945 (from https://pypi.org/simple/torch-cluster/), version: 1.4.0\n",
            "  Found link https://files.pythonhosted.org/packages/2f/0c/77453228c248e8071d185940ecb3dd9eca3cac180767bde75b2bc05c0c65/torch_cluster-1.4.1.tar.gz#sha256=e7a900d54cb2dc241c84b1da382f358399880c61290f7be72babf98500496494 (from https://pypi.org/simple/torch-cluster/), version: 1.4.1\n",
            "  Found link https://files.pythonhosted.org/packages/33/38/60ad2fcb735123429b3e0b165a19c80c6273d679b01d6550782abcb314e2/torch_cluster-1.4.2.tar.gz#sha256=ed437ec01f431d0f36398cc321524aac27870cc09e7a5a869726af9c15ac354a (from https://pypi.org/simple/torch-cluster/), version: 1.4.2\n",
            "  Found link https://files.pythonhosted.org/packages/7e/30/b315f136648801433ce6b2724fe3bfaae3c0f8a13282aa58d38ad2a8a3db/torch_cluster-1.4.3a1.tar.gz#sha256=680e47ee41a0cec223c179ce3ea2174de48ac6a277eced453ccadf4bdd2f51c9 (from https://pypi.org/simple/torch-cluster/), version: 1.4.3a1\n",
            "  Found link https://files.pythonhosted.org/packages/49/0d/f7151fb6aad5c9b0e032e46c0678e0404870de4add35b0723fc2a5c4af35/torch_cluster-1.4.3.tar.gz#sha256=340eaf9e31a7a0618f2c3d61c480e1d74466c930827f10fee86d11d8c5b85cba (from https://pypi.org/simple/torch-cluster/), version: 1.4.3\n",
            "  Found link https://files.pythonhosted.org/packages/bd/5f/01c5799cd1f81f9956f03a0e1d9a861e020a598dd411d9bd3c3c1dd5b8a4/torch_cluster-1.4.4.tar.gz#sha256=7907f3f270116cb299bdd4f88de497a85b3b34cf127910ffe0a6131e16620123 (from https://pypi.org/simple/torch-cluster/), version: 1.4.4\n",
            "  Found link https://files.pythonhosted.org/packages/c3/70/1d827d6fd1e03bb5ae84852dd0070c6574105c37e7b935284f6e990932db/torch_cluster-1.4.5.tar.gz#sha256=cf5b9363d82173bb26bb966ba93712c3262765a3a4d25c003479732a9260c257 (from https://pypi.org/simple/torch-cluster/), version: 1.4.5\n",
            "Given no hashes to check 21 links for project 'torch-cluster': discarding no candidates\n",
            "Using version 1.4.5 (newest of versions: 0.1.1, 0.2.3, 0.2.4, 1.0.1, 1.0.3, 1.1.1, 1.1.2, 1.1.3, 1.1.4, 1.1.5, 1.2.1, 1.2.2, 1.2.3, 1.2.4, 1.3.0, 1.4.0, 1.4.1, 1.4.2, 1.4.3, 1.4.4, 1.4.5)\n",
            "Collecting torch-cluster\n",
            "  Created temporary directory: /tmp/pip-unpack-7afpsdt7\n",
            "  Starting new HTTPS connection (1): files.pythonhosted.org:443\n",
            "  https://files.pythonhosted.org:443 \"GET /packages/c3/70/1d827d6fd1e03bb5ae84852dd0070c6574105c37e7b935284f6e990932db/torch_cluster-1.4.5.tar.gz HTTP/1.1\" 200 18790\n",
            "  Downloading https://files.pythonhosted.org/packages/c3/70/1d827d6fd1e03bb5ae84852dd0070c6574105c37e7b935284f6e990932db/torch_cluster-1.4.5.tar.gz\n",
            "  Added torch-cluster from https://files.pythonhosted.org/packages/c3/70/1d827d6fd1e03bb5ae84852dd0070c6574105c37e7b935284f6e990932db/torch_cluster-1.4.5.tar.gz#sha256=cf5b9363d82173bb26bb966ba93712c3262765a3a4d25c003479732a9260c257 to build tracker '/tmp/pip-req-tracker-z7g757ut'\n",
            "    Running setup.py (path:/tmp/pip-install-tr7fm8oe/torch-cluster/setup.py) egg_info for package torch-cluster\n",
            "    Running command python setup.py egg_info\n",
            "    running egg_info\n",
            "    creating /tmp/pip-install-tr7fm8oe/torch-cluster/pip-egg-info/torch_cluster.egg-info\n",
            "    writing /tmp/pip-install-tr7fm8oe/torch-cluster/pip-egg-info/torch_cluster.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-install-tr7fm8oe/torch-cluster/pip-egg-info/torch_cluster.egg-info/dependency_links.txt\n",
            "    writing requirements to /tmp/pip-install-tr7fm8oe/torch-cluster/pip-egg-info/torch_cluster.egg-info/requires.txt\n",
            "    writing top-level names to /tmp/pip-install-tr7fm8oe/torch-cluster/pip-egg-info/torch_cluster.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-install-tr7fm8oe/torch-cluster/pip-egg-info/torch_cluster.egg-info/SOURCES.txt'\n",
            "    reading manifest file '/tmp/pip-install-tr7fm8oe/torch-cluster/pip-egg-info/torch_cluster.egg-info/SOURCES.txt'\n",
            "    reading manifest template 'MANIFEST.in'\n",
            "    writing manifest file '/tmp/pip-install-tr7fm8oe/torch-cluster/pip-egg-info/torch_cluster.egg-info/SOURCES.txt'\n",
            "  Source in /tmp/pip-install-tr7fm8oe/torch-cluster has version 1.4.5, which satisfies requirement torch-cluster from https://files.pythonhosted.org/packages/c3/70/1d827d6fd1e03bb5ae84852dd0070c6574105c37e7b935284f6e990932db/torch_cluster-1.4.5.tar.gz#sha256=cf5b9363d82173bb26bb966ba93712c3262765a3a4d25c003479732a9260c257\n",
            "  Removed torch-cluster from https://files.pythonhosted.org/packages/c3/70/1d827d6fd1e03bb5ae84852dd0070c6574105c37e7b935284f6e990932db/torch_cluster-1.4.5.tar.gz#sha256=cf5b9363d82173bb26bb966ba93712c3262765a3a4d25c003479732a9260c257 from build tracker '/tmp/pip-req-tracker-z7g757ut'\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-cluster) (1.3.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-cluster) (1.17.4)\n",
            "Building wheels for collected packages: torch-cluster\n",
            "  Created temporary directory: /tmp/pip-wheel-jaer71ia\n",
            "  Building wheel for torch-cluster (setup.py) ... \u001b[?25l  Destination directory: /tmp/pip-wheel-jaer71ia\n",
            "  Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-tr7fm8oe/torch-cluster/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-tr7fm8oe/torch-cluster/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-jaer71ia --python-tag cp36\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib.linux-x86_64-3.6\n",
            "  creating build/lib.linux-x86_64-3.6/torch_cluster\n",
            "  copying torch_cluster/sampler.py -> build/lib.linux-x86_64-3.6/torch_cluster\n",
            "  copying torch_cluster/__init__.py -> build/lib.linux-x86_64-3.6/torch_cluster\n",
            "  copying torch_cluster/graclus.py -> build/lib.linux-x86_64-3.6/torch_cluster\n",
            "  copying torch_cluster/nearest.py -> build/lib.linux-x86_64-3.6/torch_cluster\n",
            "  copying torch_cluster/rw.py -> build/lib.linux-x86_64-3.6/torch_cluster\n",
            "  copying torch_cluster/radius.py -> build/lib.linux-x86_64-3.6/torch_cluster\n",
            "  copying torch_cluster/grid.py -> build/lib.linux-x86_64-3.6/torch_cluster\n",
            "  copying torch_cluster/knn.py -> build/lib.linux-x86_64-3.6/torch_cluster\n",
            "  copying torch_cluster/fps.py -> build/lib.linux-x86_64-3.6/torch_cluster\n",
            "  creating build/lib.linux-x86_64-3.6/test\n",
            "  copying test/__init__.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/utils.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_sampler.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_graclus.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_knn.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_rw.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_grid.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_nearest.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_fps.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_radius.py -> build/lib.linux-x86_64-3.6/test\n",
            "  running build_ext\n",
            "  building 'torch_cluster.graclus_cpu' extension\n",
            "  creating build/temp.linux-x86_64-3.6\n",
            "  creating build/temp.linux-x86_64-3.6/cpu\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c cpu/graclus.cpp -o build/temp.linux-x86_64-3.6/cpu/graclus.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=graclus_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cpu/graclus.o -o build/lib.linux-x86_64-3.6/torch_cluster/graclus_cpu.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.grid_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c cpu/grid.cpp -o build/temp.linux-x86_64-3.6/cpu/grid.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=grid_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cpu/grid.o -o build/lib.linux-x86_64-3.6/torch_cluster/grid_cpu.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.fps_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c cpu/fps.cpp -o build/temp.linux-x86_64-3.6/cpu/fps.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fps_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cpu/fps.o -o build/lib.linux-x86_64-3.6/torch_cluster/fps_cpu.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.rw_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c cpu/rw.cpp -o build/temp.linux-x86_64-3.6/cpu/rw.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=rw_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cpu/rw.o -o build/lib.linux-x86_64-3.6/torch_cluster/rw_cpu.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.sampler_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c cpu/sampler.cpp -o build/temp.linux-x86_64-3.6/cpu/sampler.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=sampler_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cpu/sampler.o -o build/lib.linux-x86_64-3.6/torch_cluster/sampler_cpu.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.graclus_cuda' extension\n",
            "  creating build/temp.linux-x86_64-3.6/cuda\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/graclus.cpp -o build/temp.linux-x86_64-3.6/cuda/graclus.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=graclus_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/graclus_kernel.cu -o build/temp.linux-x86_64-3.6/cuda/graclus_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=graclus_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cuda/graclus.o build/temp.linux-x86_64-3.6/cuda/graclus_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/torch_cluster/graclus_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.grid_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/grid.cpp -o build/temp.linux-x86_64-3.6/cuda/grid.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=grid_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/grid_kernel.cu -o build/temp.linux-x86_64-3.6/cuda/grid_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=grid_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cuda/grid.o build/temp.linux-x86_64-3.6/cuda/grid_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/torch_cluster/grid_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.fps_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/fps.cpp -o build/temp.linux-x86_64-3.6/cuda/fps.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fps_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/fps_kernel.cu -o build/temp.linux-x86_64-3.6/cuda/fps_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fps_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cuda/fps.o build/temp.linux-x86_64-3.6/cuda/fps_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/torch_cluster/fps_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.nearest_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/nearest.cpp -o build/temp.linux-x86_64-3.6/cuda/nearest.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=nearest_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/nearest_kernel.cu -o build/temp.linux-x86_64-3.6/cuda/nearest_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=nearest_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cuda/nearest.o build/temp.linux-x86_64-3.6/cuda/nearest_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/torch_cluster/nearest_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.knn_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/knn.cpp -o build/temp.linux-x86_64-3.6/cuda/knn.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=knn_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/knn_kernel.cu -o build/temp.linux-x86_64-3.6/cuda/knn_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=knn_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cuda/knn.o build/temp.linux-x86_64-3.6/cuda/knn_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/torch_cluster/knn_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.radius_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/radius.cpp -o build/temp.linux-x86_64-3.6/cuda/radius.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=radius_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/radius_kernel.cu -o build/temp.linux-x86_64-3.6/cuda/radius_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=radius_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cuda/radius.o build/temp.linux-x86_64-3.6/cuda/radius_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/torch_cluster/radius_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.rw_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/rw.cpp -o build/temp.linux-x86_64-3.6/cuda/rw.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=rw_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/rw_kernel.cu -o build/temp.linux-x86_64-3.6/cuda/rw_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=rw_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cuda/rw.o build/temp.linux-x86_64-3.6/cuda/rw_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/torch_cluster/rw_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/fps_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/grid_cpu.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/sampler.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/nearest_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/__init__.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/graclus.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/graclus_cpu.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/knn_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/radius_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/sampler_cpu.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/rw_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/nearest.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/rw.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/graclus_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/radius.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/rw_cpu.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/grid.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/grid_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/fps_cpu.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/knn.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/fps.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  creating build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/__init__.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/utils.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_sampler.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_graclus.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_knn.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_rw.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_grid.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_nearest.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_fps.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_radius.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  writing torch_cluster.egg-info/PKG-INFO\n",
            "  writing dependency_links to torch_cluster.egg-info/dependency_links.txt\n",
            "  writing requirements to torch_cluster.egg-info/requires.txt\n",
            "  writing top-level names to torch_cluster.egg-info/top_level.txt\n",
            "  reading manifest file 'torch_cluster.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  writing manifest file 'torch_cluster.egg-info/SOURCES.txt'\n",
            "  Copying torch_cluster.egg-info to build/bdist.linux-x86_64/wheel/torch_cluster-1.4.5-py3.6.egg-info\n",
            "  running install_scripts\n",
            "  adding license file \"LICENSE\" (matched pattern \"LICEN[CS]E*\")\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_cluster-1.4.5.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-jaer71ia/torch_cluster-1.4.5-cp36-cp36m-linux_x86_64.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'test/__init__.py'\n",
            "  adding 'test/test_fps.py'\n",
            "  adding 'test/test_graclus.py'\n",
            "  adding 'test/test_grid.py'\n",
            "  adding 'test/test_knn.py'\n",
            "  adding 'test/test_nearest.py'\n",
            "  adding 'test/test_radius.py'\n",
            "  adding 'test/test_rw.py'\n",
            "  adding 'test/test_sampler.py'\n",
            "  adding 'test/utils.py'\n",
            "  adding 'torch_cluster/__init__.py'\n",
            "  adding 'torch_cluster/fps.py'\n",
            "  adding 'torch_cluster/fps_cpu.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/fps_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/graclus.py'\n",
            "  adding 'torch_cluster/graclus_cpu.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/graclus_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/grid.py'\n",
            "  adding 'torch_cluster/grid_cpu.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/grid_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/knn.py'\n",
            "  adding 'torch_cluster/knn_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/nearest.py'\n",
            "  adding 'torch_cluster/nearest_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/radius.py'\n",
            "  adding 'torch_cluster/radius_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/rw.py'\n",
            "  adding 'torch_cluster/rw_cpu.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/rw_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/sampler.py'\n",
            "  adding 'torch_cluster/sampler_cpu.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster-1.4.5.dist-info/LICENSE'\n",
            "  adding 'torch_cluster-1.4.5.dist-info/METADATA'\n",
            "  adding 'torch_cluster-1.4.5.dist-info/WHEEL'\n",
            "  adding 'torch_cluster-1.4.5.dist-info/top_level.txt'\n",
            "  adding 'torch_cluster-1.4.5.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "\u001b[?25hdone\n",
            "  Created wheel for torch-cluster: filename=torch_cluster-1.4.5-cp36-cp36m-linux_x86_64.whl size=16219411 sha256=696d8c15db147abbf94088e8f564507e03f4ffb8e42c41b8b6c452c130823958\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-p0hposwq/wheels/0a/26/7e/a6d6a80eae5ca39b92bc77773f36cf433d5085de18014382b1\n",
            "  Removing source in /tmp/pip-install-tr7fm8oe/torch-cluster\n",
            "Successfully built torch-cluster\n",
            "Installing collected packages: torch-cluster\n",
            "\n",
            "Successfully installed torch-cluster-1.4.5\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-z7g757ut'\n",
            "Collecting torch-geometric\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/50/0a802f0bfa68058bf025d219ec6fbe806a5b891bba6702e28be7b83679fb/torch_geometric-1.3.2.tar.gz (126kB)\n",
            "\u001b[K     || 133kB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.17.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.3.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.21.0)\n",
            "Collecting plyfile\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/15/434d1d96f9a41fea56cb3290718123d651c56c4b7e53f0249acaf1bf34b6/plyfile-0.7.1.tar.gz\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.25.3)\n",
            "Collecting rdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/fe/630bacb652680f6d481b9febbb3e2c3869194a1a5fc3401a4a41195a2f8f/rdflib-4.2.2-py3-none-any.whl (344kB)\n",
            "\u001b[K     || 348kB 40.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.8.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->torch-geometric) (4.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->torch-geometric) (0.14.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (2.4.5)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     || 51kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->torch-geometric) (1.12.0)\n",
            "Building wheels for collected packages: torch-geometric, plyfile\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-1.3.2-cp36-none-any.whl size=203339 sha256=ea803298ff301abce3a08fb15c28a35d48e0d6295b9f9dee3c396e540c1a2b59\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/75/0a/56a0fd58efac6d990782523e20e61c9307fc42c31564d40348\n",
            "  Building wheel for plyfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for plyfile: filename=plyfile-0.7.1-cp36-none-any.whl size=32827 sha256=aa3f08bb12c22b4705b22f9a44c4d27e16303e90fbd2047f545e323a89dea43b\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/0d/bf/6d603d81b98604d2ecfd5e99d4ab7c9af664fd5285ab82bbb0\n",
            "Successfully built torch-geometric plyfile\n",
            "Installing collected packages: plyfile, isodate, rdflib, torch-geometric\n",
            "Successfully installed isodate-0.6.0 plyfile-0.7.1 rdflib-4.2.2 torch-geometric-1.3.2\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/5c/e918d9f190baab8d55bad52840d8091dd5114cc99f03eaa6d72d404503cc/tensorboardX-1.9-py2.py3-none-any.whl (190kB)\n",
            "\u001b[K     || 194kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.17.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (42.0.2)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-1.9\n",
            "--2019-12-10 08:56:23--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.4.11.55, 52.201.75.180, 35.153.11.252, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.4.11.55|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ngrok-stable-linux-amd64.zip\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  14.4MB/s    in 0.9s    \n",
            "\n",
            "2019-12-10 08:56:24 (14.4 MB/s) - ngrok-stable-linux-amd64.zip saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STDeeipoLBCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch_geometric.data import InMemoryDataset\n",
        "from torch_geometric.data import Data\n",
        "import os.path as osp\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guFJsTigq0bS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_optimizer(args, params):\n",
        "    weight_decay = args.weight_decay\n",
        "    filter_fn = filter(lambda p : p.requires_grad, params)\n",
        "    if args.opt == 'adam':\n",
        "        optimizer = optim.Adam(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "    elif args.opt == 'sgd':\n",
        "        optimizer = optim.SGD(filter_fn, lr=args.lr, momentum=0.95, weight_decay=weight_decay)\n",
        "    elif args.opt == 'rmsprop':\n",
        "        optimizer = optim.RMSprop(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "    elif args.opt == 'adagrad':\n",
        "        optimizer = optim.Adagrad(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "    if args.opt_scheduler == 'none':\n",
        "        return None, optimizer\n",
        "    elif args.opt_scheduler == 'step':\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.opt_decay_step, gamma=args.opt_decay_rate)\n",
        "    elif args.opt_scheduler == 'cos':\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.opt_restart)\n",
        "    return scheduler, optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzQL0UJMqva1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.nn as pyg_nn\n",
        "import torch_geometric.utils as pyg_utils\n",
        "\n",
        "class GNNStack(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, args, task='node'):\n",
        "        super(GNNStack, self).__init__()\n",
        "        conv_model = self.build_conv_model(args.model_type)\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.convs.append(conv_model(input_dim, hidden_dim))\n",
        "        assert (args.num_layers >= 1), 'Number of layers is not >=1'\n",
        "\n",
        "        for l in range(args.num_layers-1):\n",
        "            self.convs.append(conv_model(hidden_dim, hidden_dim))\n",
        "\n",
        "        # post-message-passing\n",
        "        self.post_mp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim), nn.Dropout(args.dropout), \n",
        "            nn.Linear(hidden_dim, output_dim))\n",
        "\n",
        "        self.task = task\n",
        "        if not (self.task == 'node' or self.task == 'graph'):\n",
        "            raise RuntimeError('Unknown task.')\n",
        "\n",
        "        self.dropout = args.dropout\n",
        "        self.num_layers = args.num_layers\n",
        "\n",
        "    def build_conv_model(self, model_type):\n",
        "        if model_type == 'GCN':\n",
        "            return pyg_nn.GCNConv\n",
        "        elif model_type == 'GraphSage':\n",
        "            return GraphSage\n",
        "        elif model_type == 'GAT':\n",
        "            # When applying GAT with num heads > 1, one needs to modify the \n",
        "            # input and output dimension of the conv layers (self.convs),\n",
        "            # to ensure that the input dim of the next layer is num heads\n",
        "            # multiplied by the output dim of the previous layer.\n",
        "            # HINT: In case you want to play with multiheads, you need to change the for-loop when builds up self.convs to be\n",
        "            # self.convs.append(conv_model(hidden_dim * num_heads, hidden_dim)), \n",
        "            # and also the first nn.Linear(hidden_dim * num_heads, hidden_dim) in post-message-passing.\n",
        "            return GAT\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        batch = len(data)\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Each layer in GNN should consist of a convolution (specified in model_type),\n",
        "        # a non-linearity (use RELU), and dropout. \n",
        "        # HINT: the __init__ function contains parameters you will need. For whole\n",
        "        # graph classification (as specified in self.task) apply max pooling over\n",
        "        # all of the nodes with pyg_nn.global_max_pool as the final layer.\n",
        "        # Our implementation is ~6 lines, but don't worry if you deviate from this.\n",
        "\n",
        "        \n",
        "        for i in range(self.num_layers):\n",
        "            x = self.convs[i](x, edge_index)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training = self.training)\n",
        "\n",
        "        # pools\n",
        "        if self.task == 'graph':\n",
        "            x = pyg_nn.global_mean_pool(x, batch)\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        x = self.post_mp(x)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "    def loss(self, pred, label):\n",
        "        return F.nll_loss(pred, label)\n",
        "\n",
        "\n",
        "class GraphSage(pyg_nn.MessagePassing):\n",
        "    \"\"\"Non-minibatch version of GraphSage.\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, reducer='mean', \n",
        "                 normalize_embedding=True):\n",
        "        super(GraphSage, self).__init__(aggr='mean')\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Define the layers needed for the message and update functions below.\n",
        "        # self.lin is the linear transformation that you apply to each neighbor before aggregating them\n",
        "        # self.agg_lin is the linear transformation you apply to the concatenated self embedding (skip connection) and mean aggregated neighbors\n",
        "        # Our implementation is ~2 lines, but don't worry if you deviate from this.\n",
        "\n",
        "        self.agg_lin = nn.Linear(in_channels + out_channels, out_channels, bias = False) # TODO\n",
        "        self.lin = nn.Linear(in_channels, out_channels) # TODO\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        if normalize_embedding:\n",
        "            self.normalize_emb = True\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        num_nodes = x.size(0)\n",
        "        # x has shape [N, in_channels]\n",
        "        # edge_index has shape [2, E]\n",
        "\n",
        "        return self.propagate(edge_index, size=(num_nodes, num_nodes), x=x)\n",
        "\n",
        "    def message(self, x_j, edge_index, size):\n",
        "        # x_j has shape [E, in_channels]\n",
        "        # edge_index has shape [2, E]\n",
        "        \n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Given x_j, perform the aggregation of a dense layer followed by a RELU non-linearity.\n",
        "        # Notice that the aggregator operation will be done in self.propagate. \n",
        "        # HINT: It may be useful to read the pyg_nn implementation of GCNConv,\n",
        "        # https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html\n",
        "        # Our implementation is ~1 line, but don't worry if you deviate from this.\n",
        "\n",
        "        x_j = self.lin(x_j) # TODO\n",
        "        x_j = F.relu(x_j)\n",
        "\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        return x_j\n",
        "\n",
        "    def update(self, aggr_out, x):\n",
        "        # aggr_out has shape [N, out_channels]\n",
        "        # x has shape [N, in_channels]\n",
        "        \n",
        "        ############################################################################\n",
        "        # TODO: Your code here! Perform the update step here. \n",
        "        # Perform a MLP with skip-connection, that is a concatenation followed by \n",
        "        # a linear layer and a RELU non-linearity.\n",
        "        # Finally, remember to normalize as vector as shown in GraphSage algorithm.\n",
        "        # Our implementation is ~4 lines, but don't worry if you deviate from this.\n",
        "        \n",
        "        if self.normalize_emb:\n",
        "            aggr_out = torch.cat((aggr_out, x), 1)\n",
        "            aggr_out = self.agg_lin(aggr_out)\n",
        "            aggr_out = F.relu(aggr_out)\n",
        "            aggr_out = F.normalize(aggr_out) # TODO\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        return aggr_out\n",
        "\n",
        "\n",
        "class GAT(pyg_nn.MessagePassing):\n",
        "    # Please run code with num_heads=1. \n",
        "    def __init__(self, in_channels, out_channels, num_heads=1, concat=True,\n",
        "                 dropout=0, bias=True, **kwargs):\n",
        "        super(GAT, self).__init__(aggr='add', **kwargs)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.heads = num_heads\n",
        "        self.concat = concat \n",
        "        self.dropout = dropout\n",
        "\n",
        "        ############################################################################\n",
        "        #  TODO: Your code here!\n",
        "        # Use nn.Linear the layers needed for the forward function. \n",
        "        # Remember that the shape of the output depends on the number of heads and out_channels.\n",
        "        # Our implementation is ~1 line, but don't worry if you deviate from this.\n",
        "\n",
        "        self.lin = nn.Linear(in_channels, self.heads*out_channels) # TODO\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        ############################################################################\n",
        "        #  TODO: Your code here!\n",
        "        # The attention mechanism is a single feed-forward neural network parametrized\n",
        "        # by weight vector self.att. Define self.att using nn.Parameter needed for the attention\n",
        "        # mechanism here. Remember to consider number of heads and out_channels for dimension!\n",
        "        # Also remember that that the attention mechanism is applied to the concatenation\n",
        "        # of node feaures of two nodes for dimension.\n",
        "        # Our implementation is ~1 line, but don't worry if you deviate from this.\n",
        "\n",
        "        self.att = nn.Parameter(torch.Tensor(2*out_channels, 1))\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        if bias and concat:\n",
        "            self.bias = nn.Parameter(torch.Tensor(self.heads * out_channels))\n",
        "        elif bias and not concat:\n",
        "            self.bias = nn.Parameter(torch.Tensor(out_channels))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "\n",
        "        nn.init.xavier_uniform_(self.att)\n",
        "        nn.init.zeros_(self.bias)\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "    def forward(self, x, edge_index, size=None):\n",
        "        # x has shape [N, in_channels]\n",
        "        # edge_index has shape [2, E]\n",
        "        \n",
        "        ############################################################################\n",
        "        #  TODO: Your code here!\n",
        "        # Apply your linear transformation to the node feature matrix x before starting\n",
        "        # to propagate messages.\n",
        "        # Our implementation is ~1 line, but don't worry if you deviate from this.\n",
        "        \n",
        "        x = self.lin(x) # TODO\n",
        "        ############################################################################\n",
        "\n",
        "        # Start propagating messages.\n",
        "        return self.propagate(edge_index, size=size, x=x)\n",
        "\n",
        "    def message(self, edge_index_i, x_i, x_j, size_i):\n",
        "        # Constructs messages to node i for each edge (j, i).\n",
        "        # edge_index_i has shape [E]\n",
        "        \n",
        "        ############################################################################\n",
        "        #  TODO: Your code here! Compute the attention coefficients alpha as described\n",
        "        # in equation (7). Remember to be careful of the number of heads with dimension!\n",
        "        # HINT: torch_geometric.utils.softmax may help to calculate softmax for neighbors of i. \n",
        "        # https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.softmax\n",
        "        # Our implementation is ~5 lines, but don't worry if you deviate from this.\n",
        "        \n",
        "        x_i = x_i.view(-1, self.heads, self.out_channels)\n",
        "        x_j = x_j.view(-1, self.heads, self.out_channels)\n",
        "        \n",
        "        e_ij = torch.cat([x_i, x_j], dim = 2)\n",
        "        e_ij = torch.einsum(\"abc,cd->abd\", (e_ij, self.att))\n",
        "        \n",
        "        m = nn.LeakyReLU(0.2)\n",
        "        e_ij = m(e_ij)\n",
        "\n",
        "        alpha = pyg_utils.softmax(e_ij, edge_index_i) # TODO\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n",
        "\n",
        "        return x_j * alpha.view(-1, self.heads, 1)\n",
        "        \n",
        "    def update(self, aggr_out):\n",
        "        # Updates node embedings.\n",
        "        if self.concat is True:\n",
        "            aggr_out = aggr_out.view(-1, self.heads * self.out_channels)\n",
        "        else:\n",
        "            aggr_out = aggr_out.mean(dim=1)\n",
        "\n",
        "        if self.bias is not None:\n",
        "            aggr_out = aggr_out + self.bias\n",
        "        return aggr_out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucAnFus2hqfK",
        "colab_type": "code",
        "outputId": "c608efaa-b54a-4db3-9ae2-959f735de103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0vXQNT5K9ks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_obj():\n",
        "  edges = open(\"drive/My Drive/CS224W/Colab Notebooks/edges-100k.txt\", 'r').readlines()\n",
        "  labels = open(\"drive/My Drive/CS224W/Colab Notebooks/labels_final.txt\", 'r').readlines()\n",
        "  source_nodes = []\n",
        "  target_nodes = []\n",
        "\n",
        "  for line in edges:\n",
        "    x = line.split()\n",
        "    source_nodes.append(int(x[0]))\n",
        "    target_nodes.append(int(x[1]))\n",
        "\n",
        "  labels = [int(line) for line in labels]\n",
        "\n",
        "  features = [[1]*NUM_FEATURES for i in range(len(labels))]\n",
        "  x = torch.tensor(features, dtype=torch.float)\n",
        "\n",
        "  y = torch.LongTensor(labels) #dtype=torch.long\n",
        "\n",
        "  edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
        "\n",
        "  data = Data(x=x, edge_index=edge_index, y=y, batch=torch.tensor([i for i in range(len(labels))])) # num_classes = NUM_LABELS\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogDp4jyLqfd2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.data import DataLoader\n",
        "\n",
        "import torch_geometric.nn as pyg_nn\n",
        "\n",
        "NUM_FEATURES = 1433\n",
        "NUM_LABELS = 21\n",
        "\n",
        "GCN_acc = []\n",
        "GraphSage_acc = []\n",
        "GAT_acc = []\n",
        "\n",
        "def train(dataset, task, args):\n",
        "\n",
        "    # build model\n",
        "    model = GNNStack(NUM_FEATURES, args.hidden_dim, NUM_LABELS, args, task=task)\n",
        "    scheduler, opt = build_optimizer(args, model.parameters())\n",
        "\n",
        "    # train\n",
        "    for epoch in range(args.epochs):\n",
        "        total_loss = 0\n",
        "        model.train()\n",
        "        opt.zero_grad()\n",
        "        pred = model(dataset)\n",
        "        label = dataset.y\n",
        "\n",
        "        loss = model.loss(pred, label)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        total_loss += loss.item()\n",
        "        total_loss /= len(dataset)\n",
        "\n",
        "        if epoch % 5 == 0:\n",
        "            test_acc = test(dataset, model, args)\n",
        "            # print(test_acc,   '  test')\n",
        "\n",
        "            if args.model_type == 'GCN':\n",
        "              GCN_acc.append(test_acc)\n",
        "              f = open(\"drive/My Drive/CS224W/Colab Notebooks/GCN_acc.txt\", 'w')\n",
        "              f.write(str(GCN_acc).strip(\"[]\"))\n",
        "              f.close()\n",
        "\n",
        "            elif args.model_type == 'GraphSage':\n",
        "              GraphSage_acc.append(test_acc)\n",
        "              f = open(\"drive/My Drive/CS224W/Colab Notebooks/GraphSage_acc.txt\", 'w')\n",
        "              f.write(str(GraphSage_acc).strip(\"[]\"))\n",
        "              f.close()\n",
        "\n",
        "            elif args.model_type == 'GAT':\n",
        "              GAT_acc.append(test_acc)\n",
        "              f = open(\"drive/My Drive/CS224W/Colab Notebooks/GAT_acc.txt\", 'w')\n",
        "              f.write(str(GAT_acc).strip(\"[]\"))\n",
        "              f.close()\n",
        "\n",
        "def test(test_dataset, model, args):\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        # max(dim=1) returns values, indices tuple; only need indices\n",
        "        pred = model(test_dataset).max(dim=1)[1]\n",
        "        label = test_dataset.y\n",
        "\n",
        "    if args.model_type == 'GCN':  \n",
        "        f = open(\"drive/My Drive/CS224W/Colab Notebooks/GCN_pred.txt\", 'w')\n",
        "        f.write(\"pred: \" + str(pred.tolist()).strip(\"[]\") + \"\\n\")\n",
        "        f.write(\"label: \" + str(label.tolist()).strip(\"[]\") + \"\\n\")\n",
        "        f.close()\n",
        "    elif args.model_type == 'GraphSage':\n",
        "        f = open(\"drive/My Drive/CS224W/Colab Notebooks/GraphSage_pred.txt\", 'w')\n",
        "        f.write(\"pred: \" + str(pred.tolist()).strip(\"[]\") + \"\\n\")\n",
        "        f.write(\"label: \" + str(label.tolist()).strip(\"[]\") + \"\\n\")\n",
        "        f.close()\n",
        "    elif args.model_type == 'GAT':\n",
        "        f = open(\"drive/My Drive/CS224W/Colab Notebooks/GAT_pred.txt\", 'w')\n",
        "        f.write(\"pred: \" + str(pred.tolist()).strip(\"[]\") + \"\\n\")\n",
        "        f.write(\"label: \" + str(label.tolist()).strip(\"[]\") + \"\\n\")\n",
        "        f.close()\n",
        "\n",
        "    correct += pred.eq(label).sum().item()\n",
        "    total = len(label)\n",
        "    return correct / total\n",
        "\n",
        "class objectview(object):\n",
        "    def __init__(self, d):\n",
        "        self.__dict__ = d\n",
        "\n",
        "def main():\n",
        "  for args in [\n",
        "      {'model_type': 'GCN', 'num_layers': 2, 'batch_size': 32, 'hidden_dim': 32, 'dropout': 0.5, 'epochs': 200, 'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, 'weight_decay': 5e-3, 'lr': 0.01},\n",
        "      {'model_type': 'GraphSage', 'num_layers': 2, 'batch_size': 32, 'hidden_dim': 32, 'dropout': 0.5, 'epochs': 200, 'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, 'weight_decay': 5e-3, 'lr': 0.01},\n",
        "      {'model_type': 'GAT', 'num_layers': 2, 'batch_size': 32, 'hidden_dim': 32, 'dropout': 0.5, 'epochs': 200, 'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, 'weight_decay': 5e-3, 'lr': 0.01},\n",
        "  ]:\n",
        "    args = objectview(args)\n",
        "    task = 'node'\n",
        "    dataset = data_obj()\n",
        "    train(dataset, task, args)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAvQJiLukFMk",
        "colab_type": "code",
        "outputId": "903aadd6-5d91-4d0f-9d27-e0fa880df361",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.plot(GCN_acc ,label = \"GCN_acc\")\n",
        "plt.plot(GraphSage_acc ,label = \"GraphSage_acc\")\n",
        "plt.plot(GAT_acc ,label = \"GAT_acc\")\n",
        "plt.legend()\n",
        "#plt.show()\n",
        "plt.savefig(\"drive/My Drive/CS224W/Colab Notebooks/output.png\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEZFAKQBERAL1/wGqq0GHDF+q3gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}