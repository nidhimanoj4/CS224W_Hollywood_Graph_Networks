{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8e9tfWcjPUs",
        "colab_type": "text"
      },
      "source": [
        "Make a copy of this notebook. When running this notebook on Colab, ensure that you've set your Runtime > Change runtime type to Python 3 and GPU.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oLWZWPPqo-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --verbose --no-cache-dir torch-scatter\n",
        "!pip install --verbose --no-cache-dir torch-sparse\n",
        "!pip install --verbose --no-cache-dir torch-cluster\n",
        "!pip install torch-geometric\n",
        "!pip install tensorboardX\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STDeeipoLBCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch_geometric.data import InMemoryDataset\n",
        "from torch_geometric.data import Data\n",
        "import os.path as osp\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guFJsTigq0bS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_optimizer(args, params):\n",
        "    weight_decay = args.weight_decay\n",
        "    filter_fn = filter(lambda p : p.requires_grad, params)\n",
        "    if args.opt == 'adam':\n",
        "        optimizer = optim.Adam(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "    elif args.opt == 'sgd':\n",
        "        optimizer = optim.SGD(filter_fn, lr=args.lr, momentum=0.95, weight_decay=weight_decay)\n",
        "    elif args.opt == 'rmsprop':\n",
        "        optimizer = optim.RMSprop(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "    elif args.opt == 'adagrad':\n",
        "        optimizer = optim.Adagrad(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "    if args.opt_scheduler == 'none':\n",
        "        return None, optimizer\n",
        "    elif args.opt_scheduler == 'step':\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.opt_decay_step, gamma=args.opt_decay_rate)\n",
        "    elif args.opt_scheduler == 'cos':\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.opt_restart)\n",
        "    return scheduler, optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzQL0UJMqva1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.nn as pyg_nn\n",
        "import torch_geometric.utils as pyg_utils\n",
        "\n",
        "class GNNStack(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, args, task='node'):\n",
        "        super(GNNStack, self).__init__()\n",
        "        conv_model = self.build_conv_model(args.model_type)\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.convs.append(conv_model(input_dim, hidden_dim))\n",
        "        assert (args.num_layers >= 1), 'Number of layers is not >=1'\n",
        "\n",
        "        for l in range(args.num_layers-1):\n",
        "            self.convs.append(conv_model(hidden_dim, hidden_dim))\n",
        "\n",
        "        # post-message-passing\n",
        "        self.post_mp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim), nn.Dropout(args.dropout), \n",
        "            nn.Linear(hidden_dim, output_dim))\n",
        "\n",
        "        self.task = task\n",
        "        if not (self.task == 'node' or self.task == 'graph'):\n",
        "            raise RuntimeError('Unknown task.')\n",
        "\n",
        "        self.dropout = args.dropout\n",
        "        self.num_layers = args.num_layers\n",
        "\n",
        "    def build_conv_model(self, model_type):\n",
        "        if model_type == 'GCN':\n",
        "            return pyg_nn.GCNConv\n",
        "        elif model_type == 'GraphSage':\n",
        "            return GraphSage\n",
        "        elif model_type == 'GAT':\n",
        "            # When applying GAT with num heads > 1, one needs to modify the \n",
        "            # input and output dimension of the conv layers (self.convs),\n",
        "            # to ensure that the input dim of the next layer is num heads\n",
        "            # multiplied by the output dim of the previous layer.\n",
        "            # HINT: In case you want to play with multiheads, you need to change the for-loop when builds up self.convs to be\n",
        "            # self.convs.append(conv_model(hidden_dim * num_heads, hidden_dim)), \n",
        "            # and also the first nn.Linear(hidden_dim * num_heads, hidden_dim) in post-message-passing.\n",
        "            return GAT\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        batch = len(data)\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Each layer in GNN should consist of a convolution (specified in model_type),\n",
        "        # a non-linearity (use RELU), and dropout. \n",
        "        # HINT: the __init__ function contains parameters you will need. For whole\n",
        "        # graph classification (as specified in self.task) apply max pooling over\n",
        "        # all of the nodes with pyg_nn.global_max_pool as the final layer.\n",
        "        # Our implementation is ~6 lines, but don't worry if you deviate from this.\n",
        "\n",
        "        \n",
        "        for i in range(self.num_layers):\n",
        "            x = self.convs[i](x, edge_index)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training = self.training)\n",
        "\n",
        "        # pools\n",
        "        if self.task == 'graph':\n",
        "            x = pyg_nn.global_mean_pool(x, batch)\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        x = self.post_mp(x)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "    def loss(self, pred, label):\n",
        "        return F.nll_loss(pred, label)\n",
        "\n",
        "\n",
        "class GraphSage(pyg_nn.MessagePassing):\n",
        "    \"\"\"Non-minibatch version of GraphSage.\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, reducer='mean', \n",
        "                 normalize_embedding=True):\n",
        "        super(GraphSage, self).__init__(aggr='mean')\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Define the layers needed for the message and update functions below.\n",
        "        # self.lin is the linear transformation that you apply to each neighbor before aggregating them\n",
        "        # self.agg_lin is the linear transformation you apply to the concatenated self embedding (skip connection) and mean aggregated neighbors\n",
        "        # Our implementation is ~2 lines, but don't worry if you deviate from this.\n",
        "\n",
        "        self.agg_lin = nn.Linear(in_channels + out_channels, out_channels, bias = False) # TODO\n",
        "        self.lin = nn.Linear(in_channels, out_channels) # TODO\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        if normalize_embedding:\n",
        "            self.normalize_emb = True\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        num_nodes = x.size(0)\n",
        "        # x has shape [N, in_channels]\n",
        "        # edge_index has shape [2, E]\n",
        "\n",
        "        return self.propagate(edge_index, size=(num_nodes, num_nodes), x=x)\n",
        "\n",
        "    def message(self, x_j, edge_index, size):\n",
        "        # x_j has shape [E, in_channels]\n",
        "        # edge_index has shape [2, E]\n",
        "        \n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Given x_j, perform the aggregation of a dense layer followed by a RELU non-linearity.\n",
        "        # Notice that the aggregator operation will be done in self.propagate. \n",
        "        # HINT: It may be useful to read the pyg_nn implementation of GCNConv,\n",
        "        # https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html\n",
        "        # Our implementation is ~1 line, but don't worry if you deviate from this.\n",
        "\n",
        "        x_j = self.lin(x_j) # TODO\n",
        "        x_j = F.relu(x_j)\n",
        "\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        return x_j\n",
        "\n",
        "    def update(self, aggr_out, x):\n",
        "        # aggr_out has shape [N, out_channels]\n",
        "        # x has shape [N, in_channels]\n",
        "        \n",
        "        ############################################################################\n",
        "        # TODO: Your code here! Perform the update step here. \n",
        "        # Perform a MLP with skip-connection, that is a concatenation followed by \n",
        "        # a linear layer and a RELU non-linearity.\n",
        "        # Finally, remember to normalize as vector as shown in GraphSage algorithm.\n",
        "        # Our implementation is ~4 lines, but don't worry if you deviate from this.\n",
        "        \n",
        "        if self.normalize_emb:\n",
        "            aggr_out = torch.cat((aggr_out, x), 1)\n",
        "            aggr_out = self.agg_lin(aggr_out)\n",
        "            aggr_out = F.relu(aggr_out)\n",
        "            aggr_out = F.normalize(aggr_out) # TODO\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        return aggr_out\n",
        "\n",
        "\n",
        "class GAT(pyg_nn.MessagePassing):\n",
        "    # Please run code with num_heads=1. \n",
        "    def __init__(self, in_channels, out_channels, num_heads=1, concat=True,\n",
        "                 dropout=0, bias=True, **kwargs):\n",
        "        super(GAT, self).__init__(aggr='add', **kwargs)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.heads = num_heads\n",
        "        self.concat = concat \n",
        "        self.dropout = dropout\n",
        "\n",
        "        ############################################################################\n",
        "        #  TODO: Your code here!\n",
        "        # Use nn.Linear the layers needed for the forward function. \n",
        "        # Remember that the shape of the output depends on the number of heads and out_channels.\n",
        "        # Our implementation is ~1 line, but don't worry if you deviate from this.\n",
        "\n",
        "        self.lin = nn.Linear(in_channels, self.heads*out_channels) # TODO\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        ############################################################################\n",
        "        #  TODO: Your code here!\n",
        "        # The attention mechanism is a single feed-forward neural network parametrized\n",
        "        # by weight vector self.att. Define self.att using nn.Parameter needed for the attention\n",
        "        # mechanism here. Remember to consider number of heads and out_channels for dimension!\n",
        "        # Also remember that that the attention mechanism is applied to the concatenation\n",
        "        # of node feaures of two nodes for dimension.\n",
        "        # Our implementation is ~1 line, but don't worry if you deviate from this.\n",
        "\n",
        "        self.att = nn.Parameter(torch.Tensor(2*out_channels, 1))\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        if bias and concat:\n",
        "            self.bias = nn.Parameter(torch.Tensor(self.heads * out_channels))\n",
        "        elif bias and not concat:\n",
        "            self.bias = nn.Parameter(torch.Tensor(out_channels))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "\n",
        "        nn.init.xavier_uniform_(self.att)\n",
        "        nn.init.zeros_(self.bias)\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "    def forward(self, x, edge_index, size=None):\n",
        "        # x has shape [N, in_channels]\n",
        "        # edge_index has shape [2, E]\n",
        "        \n",
        "        ############################################################################\n",
        "        #  TODO: Your code here!\n",
        "        # Apply your linear transformation to the node feature matrix x before starting\n",
        "        # to propagate messages.\n",
        "        # Our implementation is ~1 line, but don't worry if you deviate from this.\n",
        "        \n",
        "        x = self.lin(x) # TODO\n",
        "        ############################################################################\n",
        "\n",
        "        # Start propagating messages.\n",
        "        return self.propagate(edge_index, size=size, x=x)\n",
        "\n",
        "    def message(self, edge_index_i, x_i, x_j, size_i):\n",
        "        # Constructs messages to node i for each edge (j, i).\n",
        "        # edge_index_i has shape [E]\n",
        "        \n",
        "        ############################################################################\n",
        "        #  TODO: Your code here! Compute the attention coefficients alpha as described\n",
        "        # in equation (7). Remember to be careful of the number of heads with dimension!\n",
        "        # HINT: torch_geometric.utils.softmax may help to calculate softmax for neighbors of i. \n",
        "        # https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.softmax\n",
        "        # Our implementation is ~5 lines, but don't worry if you deviate from this.\n",
        "        \n",
        "        x_i = x_i.view(-1, self.heads, self.out_channels)\n",
        "        x_j = x_j.view(-1, self.heads, self.out_channels)\n",
        "        \n",
        "        e_ij = torch.cat([x_i, x_j], dim = 2)\n",
        "        e_ij = torch.einsum(\"abc,cd->abd\", (e_ij, self.att))\n",
        "        \n",
        "        m = nn.LeakyReLU(0.2)\n",
        "        e_ij = m(e_ij)\n",
        "\n",
        "        alpha = pyg_utils.softmax(e_ij, edge_index_i) # TODO\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n",
        "\n",
        "        return x_j * alpha.view(-1, self.heads, 1)\n",
        "        \n",
        "    def update(self, aggr_out):\n",
        "        # Updates node embedings.\n",
        "        if self.concat is True:\n",
        "            aggr_out = aggr_out.view(-1, self.heads * self.out_channels)\n",
        "        else:\n",
        "            aggr_out = aggr_out.mean(dim=1)\n",
        "\n",
        "        if self.bias is not None:\n",
        "            aggr_out = aggr_out + self.bias\n",
        "        return aggr_out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucAnFus2hqfK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0vXQNT5K9ks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_obj():\n",
        "  edges = open(\"edges-100k.txt\", 'r').readlines()\n",
        "  labels = open(\"labels_final.txt\", 'r').readlines()\n",
        "  source_nodes = []\n",
        "  target_nodes = []\n",
        "\n",
        "  for line in edges:\n",
        "    x = line.split()\n",
        "    source_nodes.append(int(x[0]))\n",
        "    target_nodes.append(int(x[1]))\n",
        "\n",
        "  labels = [int(line) for line in labels]\n",
        "\n",
        "  features = [[1]*NUM_FEATURES for i in range(len(labels))]\n",
        "  x = torch.tensor(features, dtype=torch.float)\n",
        "\n",
        "  y = torch.LongTensor(labels) #dtype=torch.long\n",
        "\n",
        "  edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
        "\n",
        "  data = Data(x=x, edge_index=edge_index, y=y, batch=torch.tensor([i for i in range(len(labels))])) # num_classes = NUM_LABELS\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogDp4jyLqfd2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.data import DataLoader\n",
        "\n",
        "import torch_geometric.nn as pyg_nn\n",
        "\n",
        "NUM_FEATURES = 1433\n",
        "NUM_LABELS = 21\n",
        "\n",
        "GCN_acc = []\n",
        "GraphSage_acc = []\n",
        "GAT_acc = []\n",
        "\n",
        "def train(dataset, task, args):\n",
        "\n",
        "    # build model\n",
        "    model = GNNStack(NUM_FEATURES, args.hidden_dim, NUM_LABELS, args, task=task)\n",
        "    scheduler, opt = build_optimizer(args, model.parameters())\n",
        "\n",
        "    # train\n",
        "    for epoch in range(args.epochs):\n",
        "        total_loss = 0\n",
        "        model.train()\n",
        "        opt.zero_grad()\n",
        "        pred = model(dataset)\n",
        "        label = dataset.y\n",
        "\n",
        "        loss = model.loss(pred, label)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        total_loss += loss.item()\n",
        "        total_loss /= len(dataset)\n",
        "\n",
        "        if epoch % 5 == 0:\n",
        "            test_acc = test(dataset, model, args)\n",
        "            # print(test_acc,   '  test')\n",
        "\n",
        "def test(test_dataset, model, args):\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        # max(dim=1) returns values, indices tuple; only need indices\n",
        "        pred = model(test_dataset).max(dim=1)[1]\n",
        "        label = test_dataset.y\n",
        "\n",
        "    if args.model_type == 'GCN':  \n",
        "        f = open(\"GCN_pred.txt\", 'w')\n",
        "        f.write(\"pred: \" + str(pred.tolist()).strip(\"[]\") + \"\\n\")\n",
        "        f.write(\"label: \" + str(label.tolist()).strip(\"[]\") + \"\\n\")\n",
        "        f.close()\n",
        "    elif args.model_type == 'GraphSage':\n",
        "        f = open(\"GraphSage_pred.txt\", 'w')\n",
        "        f.write(\"pred: \" + str(pred.tolist()).strip(\"[]\") + \"\\n\")\n",
        "        f.write(\"label: \" + str(label.tolist()).strip(\"[]\") + \"\\n\")\n",
        "        f.close()\n",
        "    elif args.model_type == 'GAT':\n",
        "        f = open(\"GAT_pred.txt\", 'w')\n",
        "        f.write(\"pred: \" + str(pred.tolist()).strip(\"[]\") + \"\\n\")\n",
        "        f.write(\"label: \" + str(label.tolist()).strip(\"[]\") + \"\\n\")\n",
        "        f.close()\n",
        "\n",
        "    correct += pred.eq(label).sum().item()\n",
        "    total = len(label)\n",
        "    return correct / total\n",
        "\n",
        "class objectview(object):\n",
        "    def __init__(self, d):\n",
        "        self.__dict__ = d\n",
        "\n",
        "def main():\n",
        "  for args in [\n",
        "      {'model_type': 'GCN', 'num_layers': 2, 'batch_size': 32, 'hidden_dim': 32, 'dropout': 0.5, 'epochs': 200, 'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, 'weight_decay': 5e-3, 'lr': 0.01},\n",
        "      {'model_type': 'GraphSage', 'num_layers': 2, 'batch_size': 32, 'hidden_dim': 32, 'dropout': 0.5, 'epochs': 200, 'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, 'weight_decay': 5e-3, 'lr': 0.01},\n",
        "      {'model_type': 'GAT', 'num_layers': 2, 'batch_size': 32, 'hidden_dim': 32, 'dropout': 0.5, 'epochs': 200, 'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, 'weight_decay': 5e-3, 'lr': 0.01},\n",
        "  ]:\n",
        "    args = objectview(args)\n",
        "    task = 'node'\n",
        "    dataset = data_obj()\n",
        "    train(dataset, task, args)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAvQJiLukFMk",
        "colab_type": "code",
        "outputId": "903aadd6-5d91-4d0f-9d27-e0fa880df361",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.plot(GCN_acc ,label = \"GCN_acc\")\n",
        "plt.plot(GraphSage_acc ,label = \"GraphSage_acc\")\n",
        "plt.plot(GAT_acc ,label = \"GAT_acc\")\n",
        "plt.legend()\n",
        "#plt.show()\n",
        "plt.savefig(\"output.png\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEZFAKQBERAL1/wGqq0GHDF+q3gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}